#inserting record into dynamodb with lambda getting triggered by S3 json file upload
#create policy with s3, dynamodb & cloudwatch logs
#create a role & attach the newly created policy to the role
#create dynamodb table with primary key as emp_id (str)
#create lambda function with s3 as trigger --> suffix = .json
#check event in cloudwatch logs
#parse the json data in online json viewer

import json
import boto3

s3_client = boto3.client('s3')
dynamodb = boto3.resource('dynamodb').Table('employees')

def lambda_handler(event, context):
    bucket = event['Records'][0]['s3']['bucket']['name']
    json_file = event['Records'][0]['s3']['object']['key']
    json_object = s3_client.get_object(Bucket=bucket, Key=json_file)
    jsonFileReader = json_object['Body'].read()
    jsonDict = json.loads(jsonFileReader)
    # table = dynamodb.Table('employees')
    dynamodb.put_item(Item=jsonDict)

    return 'hello from lambda'
-------------------------------------------------
import boto3

dynamodb = boto3.client('dynamodb')
table = dynamodb.Table('employees')

def lambda_handler(event, context):
    with table.batch_writer() as batch:
        for x in range(10):
	    batch.put_item(
		Item={
		    'emp_id': str(x)
		    'name': "somename-{}.format(x)"		
	    	}
	    )
------------------------------------------------
#multiple record insert into dynamodb
import json
import boto3

s3_client = boto3.client('s3')
dynamodb = boto3.resource('dynamodb').Table('employees')

def lambda_handler(event, context):
    bucket = event['Records'][0]['s3']['bucket']['name']
    json_file = event['Records'][0]['s3']['object']['key']
    json_object = s3_client.get_object(Bucket=bucket, Key=json_file)
    jsonFileReader = json_object['Body'].read()
    jsonDict = json.loads(jsonFileReader)
    # table = dynamodb.Table('employees')

    with dynamodb.batch_writer() as batch:
        for emp_id in jsonDict:
            print(emp_id)
            batch.put_item(Item=emp_id)

    return {"status_code": 200, "message": "Record successfully inserted into DynamoDB"}
--------------------------------------------------
#Generating json data & writing json to a file
import json

emp_ids = ['1', '2', '4', '5']
names = ['sunny', 'shubrodeep', 'sonia', 'dipto']
age_list = [21, 30, 34, 3]
locations = ['USA', 'CANADA', 'UK', 'FRANCE']

result = []

for emp_id, name, age, location in zip(emp_ids, names, age_list, locations):
  data = {
    "emp_id": emp_id,
    "name": name,
    "age": age,
    "location": location
  }
  result.append(data)

print(result)
json_dict = json.dumps(result, indent=4)
with open("sample.json", 'w') as outfile:
  outfile.write(json_dict)
----------------------------------------------------









